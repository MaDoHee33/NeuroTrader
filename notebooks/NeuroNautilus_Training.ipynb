{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 NeuroNautilus AI Trader - Ultimate Pipeline\n",
        "\n",
        "**Version:** 2.4 (Validation Fix Edition)\n",
        "**Updated:** January 2026\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\ude80 Overview\n",
        "This notebook is the **Golden Standard** for training NeuroNautilus.\n",
        "It connects directly to your Google Drive data and pulls the latest \"Clean Architecture\" code.\n",
        "\n",
        "### \u2728 Highlights\n",
        "- **Smart Path Detection:** Auto-finds data in Drive (no more \"File Not Found\").\n",
        "- **Auto-Recovery:** Fixes \"ModuleNotFoundError\" automatically.\n",
        "- **Clean Output:** Saves models/logs to `models/` and `logs/` directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1\ufe0f\u20e3 Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title \ud83d\udd17 Connect to Google Drive (Running this is Mandatory!)\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# 1. Mount Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"\u2705 Google Drive Mounted\")\n",
        "    except:\n",
        "        print(\"\u26a0\ufe0f Failed to mount drive. Ignore if local.\")\n",
        "else:\n",
        "    print(\"\u2705 Drive already mounted\")\n",
        "\n",
        "# 2. Define Workspace (Where Data Lives)\n",
        "WORKSPACE = Path('/content/drive/MyDrive/NeuroTrader_Workspace')\n",
        "DATA_DIR = WORKSPACE / 'data'\n",
        "MODELS_DIR = WORKSPACE / 'models'\n",
        "LOGS_DIR = WORKSPACE / 'logs'\n",
        "\n",
        "# Ensure Dirs Exist (Silent if drive fail)\n",
        "try:\n",
        "    for d in [DATA_DIR, MODELS_DIR, LOGS_DIR]:\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"\\n\ud83d\udcc2 Workspace: {WORKSPACE}\")\n",
        "except:\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title \ud83d\udee0\ufe0f Install & Update Code (Auto-Fix)\n",
        "# Force Install\n",
        "!pip install -q stable-baselines3[extra] gymnasium pandas numpy ta\n",
        "!pip install -q nautilus_trader\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- AUTO-RECOVERY VS CLEANUP ---\n",
        "REPO_PATH = '/content/NeuroTrader'\n",
        "\n",
        "# If we are missing critical new structure, force re-clone\n",
        "if os.path.exists(REPO_PATH):\n",
        "    # Check if we have the new clean structure (e.g. no 'skills' folder)\n",
        "    if os.path.exists(f'{REPO_PATH}/skills'): \n",
        "        print(\"\u26a0\ufe0f Legacy structure detected! Cleaning up...\")\n",
        "        shutil.rmtree(REPO_PATH)\n",
        "        \n",
        "    # Check if imports failed previously\n",
        "    elif not os.path.exists(f'{REPO_PATH}/src/brain/data_discovery.py'):\n",
        "        print(\"\u26a0\ufe0f Corrupt install detected! Re-cloning...\")\n",
        "        shutil.rmtree(REPO_PATH)\n",
        "\n",
        "# Clone if missing\n",
        "if not os.path.exists(REPO_PATH):\n",
        "    print(\"\u2b07\ufe0f Cloning Repository...\")\n",
        "    !git clone https://github.com/MaDoHee33/NeuroTrader.git {REPO_PATH}\n",
        "else:\n",
        "    print(\"\ud83d\udd04 Updating Repository...\")\n",
        "    !cd {REPO_PATH} && git pull\n",
        "\n",
        "# Add to Python Path\n",
        "if REPO_PATH not in sys.path:\n",
        "    sys.path.insert(0, REPO_PATH)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"\u2705 Code Update Complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2\ufe0f\u20e3 Smart Data Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title \ud83d\udee0\ufe0f Debug & Fix Import Paths (Run this if you see ModuleNotFoundError)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 1. Verify Repo Path\n",
        "REPO_PATH = '/content/NeuroTrader'\n",
        "if os.path.exists(REPO_PATH):\n",
        "    print(f\"\u2705 Repo found at: {REPO_PATH}\")\n",
        "    if REPO_PATH not in sys.path:\n",
        "        sys.path.insert(0, REPO_PATH)\n",
        "        print(\"\u2705 Added Repo to System Path\")\n",
        "else:\n",
        "    print(\"\u274c Repo NOT found! Please run the Setup cell above.\")\n",
        "\n",
        "# 2. Check Critical File\n",
        "TARGET_FILE = f\"{REPO_PATH}/src/brain/data_discovery.py\"\n",
        "if os.path.exists(TARGET_FILE):\n",
        "    print(f\"\u2705 Critical file found: {TARGET_FILE}\")\n",
        "else:\n",
        "    print(f\"\u274c Custom module MISSING at: {TARGET_FILE}\")\n",
        "    print(\"   \ud83d\udc49 NUCLEAR OPTION: Forcing Hard Reset...\")\n",
        "    \n",
        "    # FORCE RESET (Fixes 'Already up to date' lie)\n",
        "    !cd {REPO_PATH} && git fetch --all\n",
        "    !cd {REPO_PATH} && git reset --hard origin/neuronautilus-v1\n",
        "    !cd {REPO_PATH} && git pull\n",
        "    \n",
        "# 3. Test Import\n",
        "try:\n",
        "    from src.brain.data_discovery import auto_configure_training\n",
        "    print(\"\u2705 Import SUCCESS! You can proceed.\")\n",
        "except ImportError as e:\n",
        "    print(f\"\u274c Import FAILED: {e}\")\n",
        "    # Force fix for loose 'src' folders\n",
        "    if os.path.exists('/content/src'):\n",
        "        print(\"\u26a0\ufe0f Found loose 'src' folder in root. Adding /content to path...\")\n",
        "        sys.path.insert(0, '/content')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title \ud83e\udd16 Auto-Discover Best Data\n",
        "from src.brain.data_discovery import auto_configure_training\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "try:\n",
        "    # 1. Determine Catalog Path (Absolute for Colab)\n",
        "    CATALOG_PATH = DATA_DIR / 'nautilus_catalog'\n",
        "    print(f\"\ud83d\udcc2 Reading Catalog from: {CATALOG_PATH}\")\n",
        "    \n",
        "    # 2. Run Auto-Config\n",
        "    config = auto_configure_training(\n",
        "        catalog_path=str(CATALOG_PATH), \n",
        "        workspace=None # We pass full path above\n",
        "    )\n",
        "    \n",
        "    # 3. Set Variables\n",
        "    BAR_TYPE = config['bar_type']\n",
        "    TRAIN_START = config['train_start']\n",
        "    TRAIN_END = config['train_end']\n",
        "    VAL_START = config['val_start']\n",
        "    VAL_END = config['val_end']\n",
        "    TEST_START = config['test_start']\n",
        "    TEST_END = config['test_end']\n",
        "    \n",
        "    print(f\"\\n\u2705 Selected Bar Type: {BAR_TYPE}\")\n",
        "    print(f\"\ud83d\udcc5 Training Range: {TRAIN_START} to {TRAIN_END}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u26a0\ufe0f Error: {e}\")\n",
        "    print(\"\ud83d\udc49 Falling back to MANUAL configuration...\")\n",
        "    # Fallback default\n",
        "    BAR_TYPE = \"XAUUSD.SIM-15-MINUTE-LAST-EXTERNAL\"\n",
        "    \n",
        "    # Define Default Dates (FIXED: Added default dates to prevent NameError)\n",
        "    TRAIN_START = pd.to_datetime(\"2020-01-01\")\n",
        "    TRAIN_END = pd.to_datetime(\"2023-01-01\")\n",
        "    VAL_START = pd.to_datetime(\"2023-01-01\")\n",
        "    VAL_END = pd.to_datetime(\"2023-06-01\")\n",
        "    TEST_START = pd.to_datetime(\"2023-06-01\")\n",
        "    TEST_END = pd.to_datetime(\"2024-01-01\")\n",
        "     \n",
        "    print(f\"\u2705 Selected (Fallback): {BAR_TYPE}\")\n",
        "    print(f\"\ud83d\udcc5 Manual Training Range: {TRAIN_START.date()} to {TRAIN_END.date()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3\ufe0f\u20e3 Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title \ud83e\udde0 Train PPO Model (10M Steps)\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from src.brain.env.trading_env import TradingEnv\n",
        "from src.brain.train import load_data, add_features\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# --- CONFIG ---\n",
        "TOTAL_TIMESTEPS = 5_000_000\n",
        "MODEL_NAME = 'ppo_neurotrader_v2'\n",
        "# --------------\n",
        "\n",
        "print(f\"\ud83d\ude80 Starting Training: {MODEL_NAME}\")\n",
        "\n",
        "# 1. Load Data\n",
        "df = load_data(str(DATA_DIR / 'nautilus_catalog'), BAR_TYPE)\n",
        "\n",
        "# FIX: Ensure timestamps are index for slicing\n",
        "if 'timestamp' in df.columns:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df = df.set_index('timestamp')\n",
        "\n",
        "df = add_features(df)\n",
        "train_df = df[(df.index >= TRAIN_START) & (df.index <= TRAIN_END)]\n",
        "print(f\"\ud83d\udcca Training Data: {len(train_df):,} bars\")\n",
        "\n",
        "# 2. Setup Env\n",
        "env = TradingEnv(train_df)\n",
        "vec_env = DummyVecEnv([lambda: env])\n",
        "\n",
        "# 3. Setup Model\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    vec_env,\n",
        "    learning_rate=3e-4,\n",
        "    n_steps=2048,\n",
        "    batch_size=64,\n",
        "    n_epochs=10,\n",
        "    gamma=0.99,\n",
        "    gae_lambda=0.95,\n",
        "    clip_range=0.2,\n",
        "    ent_coef=0.01,\n",
        "    verbose=0,\n",
        "    tensorboard_log=str(LOGS_DIR)\n",
        ")\n",
        "\n",
        "# 4. Train with Auto-Cleanup\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=1_000_000,\n",
        "    save_path=str(MODELS_DIR / 'checkpoints'),\n",
        "    name_prefix='ppo_v2',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "try:\n",
        "    model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=checkpoint_callback, progress_bar=True)\n",
        "    \n",
        "    # Save Final\n",
        "    final_path = MODELS_DIR / f\"{MODEL_NAME}.zip\"\n",
        "    model.save(str(final_path))\n",
        "    print(f\"\\n\ud83d\udcbe Model Saved: {final_path}\")\n",
        "    \n",
        "    # Cleanup\n",
        "    print(\"\ud83e\uddf9 Cleaning up old checkpoints...\")\n",
        "    for f in (MODELS_DIR / 'checkpoints').glob('ppo_v2_*.zip'):\n",
        "        f.unlink()\n",
        "    print(\"\u2728 Cleanup Done\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\u26a0\ufe0f Interrupted! Saving...\")\n",
        "    model.save(str(MODELS_DIR / f\"{MODEL_NAME}_stopped.zip\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4\ufe0f\u20e3 Validation & Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title \ud83d\udcc9 Smart Backtest & Validation\n",
        "from src.brain.model_discovery import find_best_model\n",
        "from src.neuro_nautilus.runner import simple_backtest, analyze_results\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Get Model\n",
        "best_model = find_best_model(workspace=WORKSPACE)\n",
        "if not best_model:\n",
        "    print(\"\u26a0\ufe0f No model found, using most recent file in models dir\")\n",
        "    # Fallback logic if needed\n",
        "else:\n",
        "    print(f\"\ud83c\udfc6 Best Model: {best_model.name}\")\n",
        "\n",
        "    # 2. Validation Run\n",
        "    print(f\"\\n\ud83d\udcca Validating ({VAL_START} to {VAL_END})...\")\n",
        "    res = simple_backtest(\n",
        "        data_path=str(DATA_DIR / 'nautilus_catalog'),\n",
        "        model_path=str(best_model),\n",
        "        bar_type=BAR_TYPE,\n",
        "        start_date=VAL_START,\n",
        "        end_date=VAL_END\n",
        "    )\n",
        "    \n",
        "    m = analyze_results(res)\n",
        "    print(f\"   Sharpe: {m['sharpe_ratio']:.2f} | Return: {m['total_return']:.2%}\")\n",
        "    \n",
        "    # 3. Test Run\n",
        "    print(f\"\\n\ud83e\uddea Testing ({TEST_START} to {TEST_END})...\")\n",
        "    test_res = simple_backtest(\n",
        "        data_path=str(DATA_DIR / 'nautilus_catalog'),\n",
        "        model_path=str(best_model),\n",
        "        bar_type=BAR_TYPE,\n",
        "        start_date=TEST_START,\n",
        "        end_date=TEST_END\n",
        "    )\n",
        "    \n",
        "    tm = analyze_results(test_res)\n",
        "    print(f\"   Sharpe: {tm['sharpe_ratio']:.2f} | Return: {tm['total_return']:.2%}\")\n",
        "    \n",
        "    # 4. Plot Test\n",
        "    if 'equity_curve' in test_res:\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(pd.to_datetime(test_res['equity_curve']['timestamp']), test_res['equity_curve']['balance'])\n",
        "        plt.title(f\"Test Results (Sharpe: {tm['sharpe_ratio']:.2f})\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "    # Gate\n",
        "    if tm['sharpe_ratio'] > 0.5:\n",
        "        print(\"\\n\u2705 PASSED: Ready for Paper Trading\")\n",
        "    else:\n",
        "        print(\"\\n\u274c FAILED: Needs Retraining\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "display_name": "Python 3",
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}