{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\udde0 NeuroNautilus AI Trader - Ultimate Pipeline\n",
    "\n",
    "**Version:** 1.0 (Auto-Discovery Edition)\n",
    "**Updated:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\ude80 Overview\n",
    "\n",
    "This notebook provides a complete **End-to-End Pipeline** for training and validating the NeuroNautilus AI Trading System.\n",
    "\n",
    "### \u2728 Key Features:\n",
    "- **\ud83e\udd16 Smart Auto-Discovery:** Automatically finds the best data and trained models.\n",
    "- **\ud83e\uddf9 Auto-Cleanup:** Automatically manages storage by removing intermediate checkpoints.\n",
    "- **\ud83d\udcca Robust Backtesting:** Full validation and test period analysis with equity curves.\n",
    "- **\ud83d\udee1\ufe0f Risk-Adjusted Training:** Uses research-based PPO hyperparameters.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install Dependencies & Setup Workspace\n",
    "# Force re-install if needed\n",
    "!pip install -q stable-baselines3[extra] gymnasium pandas numpy tao-ta\n",
    "!pip install -q nautilus_trader\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Mount Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IS_COLAB = True\n",
    "    print(\"\u2705 Google Drive Mounted\")\n",
    "except:\n",
    "    IS_COLAB = False\n",
    "    print(\"\ud83d\udcbb Local Environment Detected\")\n",
    "\n",
    "# Clone/Pull Repository\n",
    "if IS_COLAB:\n",
    "    if not os.path.exists('/content/NeuroTrader'):\n",
    "        !git clone https://github.com/MaDoHee33/NeuroTrader.git /content/NeuroTrader\n",
    "    else:\n",
    "        !cd /content/NeuroTrader && git pull\n",
    "\n",
    "    sys.path.insert(0, '/content/NeuroTrader')\n",
    "\n",
    "# Define Workspace\n",
    "if IS_COLAB:\n",
    "    WORKSPACE = Path('/content/drive/MyDrive/NeuroTrader_Workspace')\n",
    "    WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    WORKSPACE = Path.cwd()\n",
    "\n",
    "DATA_DIR = WORKSPACE / 'data'\n",
    "MODELS_DIR = WORKSPACE / 'models'\n",
    "LOGS_DIR = WORKSPACE / 'logs'\n",
    "\n",
    "# Create directories\n",
    "for d in [DATA_DIR, MODELS_DIR, LOGS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n\ud83d\udcc2 Workspace: {WORKSPACE}\")\n",
    "print(\"\u2705 Setup Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 Data Configuration (Auto-Discovery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Smart Data Auto-Configuration\n",
    "from src.brain.data_discovery import auto_configure_training\n",
    "\n",
    "print(\"\ud83d\udd0d Scanning for best data...\")\n",
    "\n",
    "try:\n",
    "    # Auto-configure everything\n",
    "    config = auto_configure_training(\n",
    "        catalog_path='data/nautilus_catalog',\n",
    "        workspace=WORKSPACE\n",
    "    )\n",
    "    \n",
    "    # Set global variables\n",
    "    BAR_TYPE = config['bar_type']\n",
    "    TRAIN_START = config['train_start']\n",
    "    TRAIN_END = config['train_end']\n",
    "    VAL_START = config['val_start']\n",
    "    VAL_END = config['val_end']\n",
    "    TEST_START = config['test_start']\n",
    "    TEST_END = config['test_end']\n",
    "    \n",
    "    print(f\"\\n\u2705 Data Selected: {BAR_TYPE}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Error: {e}\")\n",
    "    print(\"Please perform manual configuration or upload data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 Model Training (Research-Optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train PPO Model (10M Steps)\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from src.brain.env.trading_env import TradingEnv\n",
    "from src.brain.train import load_data, add_features\n",
    "import time\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TOTAL_TIMESTEPS = 10_000_000  # 10 Million Steps\n",
    "MODEL_NAME = \"ppo_neurotrader\"\n",
    "# ---------------------\n",
    "\n",
    "print(f\"\ud83d\ude80 Initializing Training Pipeline for {TOTAL_TIMESTEPS:,} steps...\")\n",
    "\n",
    "# 1. Load & Prep Data\n",
    "df = load_data(str(DATA_DIR / 'nautilus_catalog'), BAR_TYPE)\n",
    "df = add_features(df)\n",
    "train_df = df[(df.index >= TRAIN_START) & (df.index <= TRAIN_END)]\n",
    "\n",
    "print(f\"\ud83d\udcc9 Training Data: {len(train_df):,} bars ({TRAIN_START} to {TRAIN_END})\")\n",
    "\n",
    "# 2. Environment\n",
    "env = TradingEnv(train_df)\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# 3. Model Setup (Research Based)\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    verbose=0,\n",
    "    tensorboard_log=str(LOGS_DIR)\n",
    ")\n",
    "\n",
    "# 4. Checkpoint Callback (Auto-Cleanup Enabled)\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=1_000_000,\n",
    "    save_path=str(MODELS_DIR / 'checkpoints'),\n",
    "    name_prefix='ppo_checkpoint',\n",
    "    save_replay_buffer=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Train\n",
    "print(\"\\n\ud83c\udfc3 Training started... (This may take 5-8 hours)\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=checkpoint_callback, progress_bar=True)\n",
    "    \n",
    "    # 6. Save Final (Smart Cleanup)\n",
    "    final_path = MODELS_DIR / f\"{MODEL_NAME}.zip\"\n",
    "    model.save(str(final_path))\n",
    "    print(f\"\\n\ud83d\udcbe Final model saved: {final_path}\")\n",
    "    \n",
    "    # 7. Auto-Cleanup\n",
    "    print(\"\\n\ud83e\uddf9 Auto-cleaning intermediate checkpoints...\")\n",
    "    for ckpt in (MODELS_DIR / 'checkpoints').glob(f'ppo_checkpoint_*_steps.zip'):\n",
    "        ckpt.unlink(missing_ok=True)\n",
    "    print(\"\u2705 Cleanup complete. Only final model kept.\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\u26a0\ufe0f Training interrupted. Saving current state...\")\n",
    "    model.save(str(MODELS_DIR / f\"{MODEL_NAME}_interrupted.zip\"))\n",
    "\n",
    "elapsed = (time.time() - start_time) / 3600\n",
    "print(f\"\u23f1\ufe0f Total Time: {elapsed:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title (Optional) Visualize Training with TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"$LOGS_DIR\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Validation & Backtesting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd0d Smart Model Discovery & Validation\n",
    "from src.brain.model_discovery import find_best_model\n",
    "from src.neuro_nautilus.runner import simple_backtest, analyze_results\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Find Best Model\n",
    "best_model_path = find_best_model(workspace=WORKSPACE)\n",
    "\n",
    "if not best_model_path:\n",
    "    print(\"\u274c No trained model found!\")\n",
    "else:\n",
    "    print(f\"\u2705 Using Best Model: {best_model_path.name}\")\n",
    "    \n",
    "    # 2. Run Validation Backtest\n",
    "    print(f\"\\n\ud83d\udcca Running Validation Backtest ({VAL_START} to {VAL_END})...\")\n",
    "    \n",
    "    val_results = simple_backtest(\n",
    "        data_path=str(DATA_DIR / 'nautilus_catalog'),\n",
    "        model_path=str(best_model_path),\n",
    "        bar_type=BAR_TYPE,\n",
    "        start_date=VAL_START,\n",
    "        end_date=VAL_END,\n",
    "        initial_balance=10000\n",
    "    )\n",
    "    \n",
    "    # 3. Metrics\n",
    "    metrics = analyze_results(val_results)\n",
    "    print(f\"\\n\ud83d\udcc8 Validation Results:\")\n",
    "    print(f\"   Total Return: {metrics['total_return']:.2%}\")\n",
    "    print(f\"   Sharpe Ratio: {metrics['sharpe_ratio']:.3f}\")\n",
    "    print(f\"   Max Drawdown: {metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"   Win Rate:     {metrics['win_rate']:.2%}\")\n",
    "    \n",
    "    # 4. Plot\n",
    "    if 'equity_curve' in val_results:\n",
    "        eq = val_results['equity_curve']\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(pd.to_datetime(eq['timestamp']), eq['balance'])\n",
    "        plt.title(f'Equity Curve (Validation) - Sharpe: {metrics[\"sharpe_ratio\"]:.2f}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83e\uddea Final Test (Unseen Data)\n",
    "# Run Backtest on TEST set\n",
    "print(f\"\ud83d\udcca Running Test Backtest ({TEST_START} to {TEST_END})...\")\n",
    "\n",
    "try:\n",
    "    test_results = simple_backtest(\n",
    "        data_path=str(DATA_DIR / 'nautilus_catalog'),\n",
    "        model_path=str(best_model_path),\n",
    "        bar_type=BAR_TYPE,\n",
    "        start_date=TEST_START,\n",
    "        end_date=TEST_END,\n",
    "        initial_balance=10000\n",
    "    )\n",
    "\n",
    "    test_metrics = analyze_results(test_results)\n",
    "\n",
    "    print(f\"\\n\ud83d\udcc8 Test Results (Unseen Data):\")\n",
    "    print(f\"   Total Return: {test_metrics['total_return']:.2%}\")\n",
    "    print(f\"   Sharpe Ratio: {test_metrics['sharpe_ratio']:.3f}\")\n",
    "    print(f\"   Max Drawdown: {test_metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"   Win Rate:     {test_metrics['win_rate']:.2%}\")\n",
    "\n",
    "    # Pass/Fail\n",
    "    if test_metrics['sharpe_ratio'] > 0.5:\n",
    "        print(\"\\n\u2705 PASSED: Ready for Paper Trading (Week 2)\")\n",
    "    else:\n",
    "        print(\"\\n\u274c FAILED: Needs improvement/retraining\")\n",
    "\n",
    "    # Plot\n",
    "    if 'equity_curve' in test_results:\n",
    "        eq = test_results['equity_curve']\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(pd.to_datetime(eq['timestamp']), eq['balance'], color='green')\n",
    "        plt.title(f'Equity Curve (TEST) - Sharpe: {test_metrics[\"sharpe_ratio\"]:.2f}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Error running test backtest: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "display_name": "Python 3",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}