{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸš€ NeuroTrader PPO Training Farm (Batch Mode)\n",
                "\n",
                "Train **multiple PPO models** with randomized hyperparameters in a single run.\n",
                "\n",
                "## Features:\n",
                "- ðŸŽ² Random hyperparameters for each model\n",
                "- âš¡ SubprocVecEnv for parallel environments (better GPU utilization)\n",
                "- ðŸ“Š Auto-evaluation and ranking\n",
                "- ðŸ’¾ All models saved to Google Drive\n",
                "\n",
                "---\n",
                "\n",
                "## Before Running:\n",
                "1. **Runtime â†’ Change runtime type â†’ GPU (T4)**\n",
                "2. Have ~500MB+ free on Google Drive"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Setup Environment"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Install dependencies\n",
                "!pip install stable-baselines3[extra] gymnasium pandas pyarrow -q\n",
                "\n",
                "# Suppress warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Imports\n",
                "import os\n",
                "import json\n",
                "import time\n",
                "import shutil\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "from datetime import datetime\n",
                "\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
                "import gymnasium as gym\n",
                "from gymnasium import spaces\n",
                "\n",
                "# Check GPU\n",
                "print(f\"âœ… Setup complete!\")\n",
                "print(f\"   PyTorch: {torch.__version__}\")\n",
                "print(f\"   GPU Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Create output directory\n",
                "OUTPUT_DIR = '/content/drive/MyDrive/NeuroTrader_Models'\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "print(f\"âœ… Output directory: {OUTPUT_DIR}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. Upload Training Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Create data directory\n",
                "os.makedirs('data/raw', exist_ok=True)\n",
                "\n",
                "# Upload file\n",
                "print(\"ðŸ“¤ Please upload: XAUUSDm_M5_raw.parquet\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Move to data folder\n",
                "for filename in uploaded.keys():\n",
                "    shutil.move(filename, f'data/raw/{filename}')\n",
                "    print(f\"âœ… Saved to: data/raw/{filename}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Training Configuration\n",
                "\n",
                "Adjust the sliders below to customize your training run."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "#@title âš™ï¸ Training Settings\n",
                "\n",
                "NUM_MODELS = 5  #@param {type:\"slider\", min:1, max:10, step:1}\n",
                "STEPS_PER_MODEL = 300000  #@param {type:\"slider\", min:100000, max:1000000, step:100000}\n",
                "NUM_PARALLEL_ENVS = 4  #@param {type:\"slider\", min:1, max:8, step:1}\n",
                "\n",
                "print(\"ðŸ“‹ Training Plan:\")\n",
                "print(f\"   Models to train: {NUM_MODELS}\")\n",
                "print(f\"   Steps per model: {STEPS_PER_MODEL:,}\")\n",
                "print(f\"   Parallel envs:   {NUM_PARALLEL_ENVS}\")\n",
                "print(f\"   Total steps:     {NUM_MODELS * STEPS_PER_MODEL:,}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. Define Trading Environment"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "class TradingEnv(gym.Env):\n",
                "    \"\"\"\n",
                "    Simple Trading Environment for PPO training.\n",
                "    Actions: 0=HOLD, 1=BUY, 2=SELL\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, df, lookback=20):\n",
                "        super().__init__()\n",
                "        self.df = df.reset_index(drop=True)\n",
                "        self.lookback = lookback\n",
                "        self.current_step = lookback\n",
                "        \n",
                "        # Action space: HOLD, BUY, SELL\n",
                "        self.action_space = spaces.Discrete(3)\n",
                "        \n",
                "        # Observation space: 22 features\n",
                "        self.observation_space = spaces.Box(\n",
                "            low=-np.inf, \n",
                "            high=np.inf, \n",
                "            shape=(22,), \n",
                "            dtype=np.float32\n",
                "        )\n",
                "        \n",
                "        # Trading state\n",
                "        self.position = 0  # 0=flat, 1=long\n",
                "        self.entry_price = 0\n",
                "        self.balance = 10000\n",
                "        self.equity = 10000\n",
                "        \n",
                "    def reset(self, seed=None, options=None):\n",
                "        super().reset(seed=seed)\n",
                "        self.current_step = self.lookback\n",
                "        self.position = 0\n",
                "        self.entry_price = 0\n",
                "        self.balance = 10000\n",
                "        self.equity = 10000\n",
                "        return self._get_observation(), {}\n",
                "    \n",
                "    def _get_observation(self):\n",
                "        \"\"\"Calculate observation from price data.\"\"\"\n",
                "        window = self.df.iloc[self.current_step - self.lookback : self.current_step]\n",
                "        close = window['close'].values\n",
                "        \n",
                "        # Calculate returns\n",
                "        returns = np.diff(close) / (close[:-1] + 1e-8)\n",
                "        \n",
                "        # Build observation vector\n",
                "        observation = np.concatenate([\n",
                "            returns[-10:],  # Last 10 returns\n",
                "            [close[-1] / close[0] - 1],  # Period return\n",
                "            [(close[-1] - close.min()) / (close.max() - close.min() + 1e-8)],  # Price position\n",
                "            [np.std(returns)],  # Volatility\n",
                "            [self.position],  # Current position (0 or 1)\n",
                "            [self.equity / 10000 - 1],  # PnL percentage\n",
                "            np.zeros(7)  # Padding for 22 features\n",
                "        ])\n",
                "        \n",
                "        return observation.astype(np.float32)\n",
                "    \n",
                "    def step(self, action):\n",
                "        \"\"\"Execute one trading step.\"\"\"\n",
                "        current_price = self.df.iloc[self.current_step]['close']\n",
                "        reward = 0\n",
                "        \n",
                "        # Execute action\n",
                "        if action == 1 and self.position == 0:  # BUY\n",
                "            self.position = 1\n",
                "            self.entry_price = current_price\n",
                "            reward = 0.01  # Small entry bonus\n",
                "            \n",
                "        elif action == 2 and self.position == 1:  # SELL\n",
                "            pnl_pct = (current_price - self.entry_price) / self.entry_price\n",
                "            self.balance *= (1 + pnl_pct)\n",
                "            reward = pnl_pct * 100  # Scaled for learning\n",
                "            self.position = 0\n",
                "            self.entry_price = 0\n",
                "        \n",
                "        # Update equity\n",
                "        if self.position == 1:\n",
                "            unrealized_pnl = (current_price - self.entry_price) / self.entry_price\n",
                "            self.equity = self.balance * (1 + unrealized_pnl)\n",
                "        else:\n",
                "            self.equity = self.balance\n",
                "        \n",
                "        # Move to next step\n",
                "        self.current_step += 1\n",
                "        \n",
                "        # Check termination conditions\n",
                "        done = self.current_step >= len(self.df) - 1\n",
                "        truncated = self.equity < 5000  # Circuit breaker at -50%\n",
                "        \n",
                "        return self._get_observation(), reward, done, truncated, {'equity': self.equity}\n",
                "\n",
                "\n",
                "print(\"âœ… TradingEnv defined!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. Load Training Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Load data\n",
                "DATA_PATH = 'data/raw/XAUUSDm_M5_raw.parquet'\n",
                "DF = pd.read_parquet(DATA_PATH)\n",
                "\n",
                "# Rename column if needed\n",
                "if 'tick_volume' in DF.columns:\n",
                "    DF.rename(columns={'tick_volume': 'volume'}, inplace=True)\n",
                "\n",
                "print(f\"âœ… Loaded data: {len(DF):,} rows\")\n",
                "print(f\"   Date range: {DF.index[0]} to {DF.index[-1]}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6. Random Hyperparameter Generator"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "def generate_random_config():\n",
                "    \"\"\"\n",
                "    Generate randomized hyperparameters for model diversity.\n",
                "    Each call produces a unique configuration.\n",
                "    \"\"\"\n",
                "    config = {\n",
                "        'learning_rate': np.random.choice([1e-4, 3e-4, 5e-4, 7e-4, 1e-3]),\n",
                "        'n_steps': int(np.random.choice([512, 1024, 2048, 4096])),\n",
                "        'batch_size': int(np.random.choice([32, 64, 128, 256])),\n",
                "        'ent_coef': round(np.random.uniform(0.01, 0.1), 4),\n",
                "        'gamma': np.random.choice([0.95, 0.97, 0.99, 0.995]),\n",
                "        'gae_lambda': round(np.random.uniform(0.9, 0.99), 2),\n",
                "        'clip_range': np.random.choice([0.1, 0.2, 0.3]),\n",
                "        'n_epochs': int(np.random.choice([5, 10, 15, 20])),\n",
                "    }\n",
                "    return config\n",
                "\n",
                "# Test the generator\n",
                "print(\"ðŸŽ² Example random config:\")\n",
                "for key, value in generate_random_config().items():\n",
                "    print(f\"   {key}: {value}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7. Batch Training ðŸš€\n",
                "\n",
                "This cell trains multiple models with different random configurations."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Function to create environment (needed for SubprocVecEnv)\n",
                "def make_env():\n",
                "    return TradingEnv(DF)\n",
                "\n",
                "# Store results\n",
                "training_results = []\n",
                "\n",
                "# Determine device\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"ðŸš€ STARTING BATCH TRAINING\")\n",
                "print(f\"   Models: {NUM_MODELS}\")\n",
                "print(f\"   Steps each: {STEPS_PER_MODEL:,}\")\n",
                "print(f\"   Device: {device.upper()}\")\n",
                "print(f\"{'='*60}\\n\")\n",
                "\n",
                "total_start_time = time.time()\n",
                "\n",
                "for model_idx in range(NUM_MODELS):\n",
                "    # Generate unique seed based on current time\n",
                "    seed = int(time.time() * 1000) % 1000000\n",
                "    np.random.seed(seed)\n",
                "    \n",
                "    # Generate random config\n",
                "    config = generate_random_config()\n",
                "    \n",
                "    # Create parallel environments\n",
                "    env = SubprocVecEnv([make_env for _ in range(NUM_PARALLEL_ENVS)])\n",
                "    \n",
                "    # Create PPO model with random hyperparameters\n",
                "    model = PPO(\n",
                "        \"MlpPolicy\",\n",
                "        env,\n",
                "        device=device,\n",
                "        verbose=0,  # Quiet mode\n",
                "        seed=seed,\n",
                "        learning_rate=config['learning_rate'],\n",
                "        n_steps=config['n_steps'],\n",
                "        batch_size=config['batch_size'],\n",
                "        ent_coef=config['ent_coef'],\n",
                "        gamma=config['gamma'],\n",
                "        gae_lambda=config['gae_lambda'],\n",
                "        clip_range=config['clip_range'],\n",
                "        n_epochs=config['n_epochs']\n",
                "    )\n",
                "    \n",
                "    # Train\n",
                "    print(f\"[{model_idx+1}/{NUM_MODELS}] Training... (lr={config['learning_rate']:.0e}, ent={config['ent_coef']:.3f})\")\n",
                "    train_start = time.time()\n",
                "    model.learn(total_timesteps=STEPS_PER_MODEL, progress_bar=True)\n",
                "    train_duration = (time.time() - train_start) / 60\n",
                "    \n",
                "    # Quick evaluation on test data (last 5000 rows)\n",
                "    test_env = TradingEnv(DF[-5000:])\n",
                "    obs, _ = test_env.reset()\n",
                "    total_trades = 0\n",
                "    \n",
                "    for _ in range(4000):\n",
                "        action, _ = model.predict(obs, deterministic=True)\n",
                "        obs, reward, done, truncated, info = test_env.step(action)\n",
                "        if action in [1, 2]:\n",
                "            total_trades += 1\n",
                "        if done or truncated:\n",
                "            break\n",
                "    \n",
                "    final_return = (info['equity'] / 10000 - 1) * 100\n",
                "    \n",
                "    # Save model\n",
                "    model_name = f\"ppo_{model_idx+1:02d}_s{seed}\"\n",
                "    save_path = f\"{OUTPUT_DIR}/{model_name}\"\n",
                "    model.save(save_path)\n",
                "    \n",
                "    # Store result\n",
                "    result = {\n",
                "        'name': model_name,\n",
                "        'seed': seed,\n",
                "        'return_pct': round(final_return, 2),\n",
                "        'trades': total_trades,\n",
                "        'duration_min': round(train_duration, 1),\n",
                "        'config': config\n",
                "    }\n",
                "    training_results.append(result)\n",
                "    \n",
                "    # Cleanup\n",
                "    env.close()\n",
                "    \n",
                "    # Print result\n",
                "    print(f\"    âœ… {model_name}: {final_return:+.1f}% | {total_trades} trades | {train_duration:.1f}min\\n\")\n",
                "\n",
                "# Calculate total time\n",
                "total_duration = (time.time() - total_start_time) / 60\n",
                "\n",
                "# Save training log\n",
                "log_path = f\"{OUTPUT_DIR}/batch_training_log.json\"\n",
                "with open(log_path, 'w') as f:\n",
                "    json.dump({\n",
                "        'timestamp': datetime.now().isoformat(),\n",
                "        'total_models': NUM_MODELS,\n",
                "        'steps_per_model': STEPS_PER_MODEL,\n",
                "        'total_duration_min': round(total_duration, 1),\n",
                "        'results': training_results\n",
                "    }, f, indent=2)\n",
                "\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"ðŸŽ‰ BATCH TRAINING COMPLETE!\")\n",
                "print(f\"   Total time: {total_duration:.1f} minutes\")\n",
                "print(f\"   Models saved: {len(training_results)}\")\n",
                "print(f\"   Log file: {log_path}\")\n",
                "print(f\"{'='*60}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 8. Results Summary"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Sort by return (best first)\n",
                "sorted_results = sorted(training_results, key=lambda x: x['return_pct'], reverse=True)\n",
                "\n",
                "print(\"\\nðŸ“Š Results Ranking (Best to Worst):\")\n",
                "print(\"=\" * 50)\n",
                "for rank, result in enumerate(sorted_results, 1):\n",
                "    emoji = \"ðŸ¥‡\" if rank == 1 else \"ðŸ¥ˆ\" if rank == 2 else \"ðŸ¥‰\" if rank == 3 else \"  \"\n",
                "    print(f\"{emoji} #{rank} {result['name']}: {result['return_pct']:+.1f}% ({result['trades']} trades)\")\n",
                "\n",
                "# Best model info\n",
                "best = sorted_results[0]\n",
                "print(f\"\\nðŸ† Best Model: {best['name']}\")\n",
                "print(f\"   Return: {best['return_pct']:+.1f}%\")\n",
                "print(f\"   Trades: {best['trades']}\")\n",
                "print(f\"   Config: lr={best['config']['learning_rate']:.0e}, ent={best['config']['ent_coef']:.3f}, gamma={best['config']['gamma']}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 9. List Saved Files"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"ðŸ“ Files in output directory:\")\n",
                "print(\"-\" * 40)\n",
                "for filename in sorted(os.listdir(OUTPUT_DIR)):\n",
                "    filepath = f\"{OUTPUT_DIR}/{filename}\"\n",
                "    size_mb = os.path.getsize(filepath) / 1024 / 1024\n",
                "    print(f\"   {filename} ({size_mb:.2f} MB)\")\n",
                "\n",
                "print(f\"\\nðŸ’¡ To use these models:\")\n",
                "print(f\"   1. Download from Google Drive: MyDrive/NeuroTrader_Models/\")\n",
                "print(f\"   2. Copy to Desktop: NeuroTrader/models/farm/\")\n",
                "print(f\"   3. Run: python scripts/replay_ghosts.py --source models/farm/\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}